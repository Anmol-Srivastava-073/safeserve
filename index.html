<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>SafeServe - Face Station</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #202124;
            font-family: 'Roboto', sans-serif;
        }

        #camera-container {
            position: relative;
            width: 720px;
            height: 560px;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 10px 20px rgba(0,0,0,0.5);
            background: #000;
        }

        video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        .ui-overlay {
            position: absolute;
            bottom: 20px;
            left: 20px;
            right: 20px;
            padding: 15px;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: all 0.3s ease;
        }

        .status {
            font-weight: bold;
            color: #333;
        }

        .btn {
            background: #4285F4;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 4px;
            cursor: pointer;
            font-weight: bold;
            font-size: 14px;
        }
        
        .btn:hover { background: #3367D6; }

        /* Hidden simulation result box */
        #result-box {
            display: none;
            margin-top: 5px;
            font-size: 13px;
            color: #1a73e8;
            font-weight: normal;
        }
    </style>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
</head>
<body>

    <div id="camera-container">
        <video id="video" autoplay muted></video>
        
        <div class="ui-overlay">
            <div>
                <div class="status" id="status-text">System Status: Initializing...</div>
                <div id="result-box"></div>
            </div>
            <button class="btn" onclick="analyzeUser()">Get AI Aid</button>
        </div>
    </div>

    <script>
        const video = document.getElementById('video');
        const statusText = document.getElementById('status-text');
        const resultBox = document.getElementById('result-box');
        let isFaceDetected = false;

        // 1. Start Camera First
        startVideo();

        function startVideo() {
            statusText.innerText = "Status: Requesting Camera...";
            navigator.mediaDevices.getUserMedia({ video: {} })
                .then(stream => {
                    video.srcObject = stream;
                    statusText.innerText = "Status: Camera ON. Loading AI...";
                    loadModels();
                })
                .catch(err => {
                    console.error(err);
                    statusText.innerText = "Error: Camera Access Denied.";
                    alert("Please allow camera access.");
                });
        }

        // 2. Load Local Models (Simplified)
        async function loadModels() {
            try {
                // We use './models' to look in your local folder
                // We ONLY load the Detector and Landmarks (The files you have)
                await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
                
                // SKIPPED: faceRecognitionNet (To prevent crashing on missing files)
                
                statusText.innerText = "Status: AI Active - Waiting for Face...";
                startTracking();
            } catch (err) {
                console.error(err);
                statusText.innerText = "Error: Check 'models' folder.";
                alert("Error: Could not find model files in './models' folder.\nMake sure the folder is named 'models' and is next to index.html");
            }
        }

        // 3. The Recognition Loop
        function startTracking() {
            video.addEventListener('play', () => {
                const canvas = faceapi.createCanvasFromMedia(video);
                document.getElementById('camera-container').append(canvas);
                
                const displaySize = { width: video.clientWidth, height: video.clientHeight };
                faceapi.matchDimensions(canvas, displaySize);

                setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks();

                    // Check if face is present for our Logic
                    if (detections.length > 0) {
                        isFaceDetected = true;
                        statusText.innerText = "Status: Face Detected - Ready for Gemini";
                        statusText.style.color = "green";
                    } else {
                        isFaceDetected = false;
                        statusText.innerText = "Status: Scanning...";
                        statusText.style.color = "#333";
                    }
                    
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                }, 100);
            });
        }

        // 4. The "Fake" Gemini Integration (For Demo)
        function analyzeUser() {
            if (!isFaceDetected) {
                alert("No face detected! Please look at the camera.");
                return;
            }

            // Simulate "Processing"
            statusText.innerText = "Gemini is analyzing history...";
            
            setTimeout(() => {
                // This is where you would call the real Google Gemini API
                statusText.innerText = "Identification Complete: User #892";
                
                // Show the "Recommendation"
                resultBox.style.display = "block";
                resultBox.innerHTML = `
                    <strong>Gemini Recommendation:</strong><br/>
                    • Issue: Low temperature alert (Night)<br/>
                    • Action: Assign Thermal Blanket + Soup Kit
                `;
            }, 1500);
        }
    </script>
</body>
</html>
