<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>SafeServe - Face Station</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #202124;
            font-family: 'Roboto', sans-serif;
        }

        #camera-container {
            position: relative;
            width: 720px;
            height: 560px;
            border-radius: 12px;
            overflow: hidden;
            box-shadow: 0 10px 20px rgba(0,0,0,0.5);
            background: #000;
        }

        video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            transform: scaleX(-1);
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
            
        }

        .ui-overlay {
            position: absolute;
            bottom: 20px;
            left: 20px;
            right: 20px;
            padding: 15px;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: all 0.3s ease;
        }

        .status {
            font-weight: bold;
            color: #333;
        }

        .btn {
            background: #4285F4;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 4px;
            cursor: pointer;
            font-weight: bold;
            font-size: 14px;
        }
        
        .btn:hover { background: #3367D6; }

        /* Hidden simulation result box */
        #result-box {
            display: none;
            margin-top: 5px;
            font-size: 13px;
            color: #1a73e8;
            font-weight: normal;
        }
    </style>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
</head>
<body>

    <div id="camera-container">
        <video id="video" autoplay muted></video>
        
        <div class="ui-overlay">
            <div>
                <div class="status" id="status-text">System Status: Initializing...</div>
                <div id="result-box"></div>
            </div>
            <button class="btn" onclick="analyzeUser()">Get AI Aid</button>
        </div>
    </div>

    <script>
        const video = document.getElementById('video');
        const statusText = document.getElementById('status-text');
        const resultBox = document.getElementById('result-box');
        let isModelsLoaded = false;

        // 1. START CAMERA IMMEDIATELY
        startVideo();

        function startVideo() {
            statusText.innerText = "Status: Requesting Camera...";
            navigator.mediaDevices.getUserMedia({ video: {} })
                .then(stream => {
                    video.srcObject = stream;
                    // Wait for video to actually have dimensions
                    video.onloadedmetadata = () => {
                        statusText.innerText = "Status: Video Active. Loading AI...";
                        loadModels();
                    };
                })
                .catch(err => {
                    console.error(err);
                    alert("Camera blocked. Please allow permissions.");
                });
        }

        // 2. LOAD MODELS (Force specific parameters)
        async function loadModels() {
            try {
                // Point to your local folder
                await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('./models');
                
                statusText.innerText = "Status: Models Loaded. Starting Loop...";
                isModelsLoaded = true;
                startTracking();
            } catch (err) {
                console.error(err);
                statusText.innerText = "Error: Model files missing in './models'";
                statusText.style.color = "red";
                alert("CRITICAL ERROR: Could not find model files. Check console.");
            }
        }

        // 3. TRACKING LOOP (Debug Mode)
        function startTracking() {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.getElementById('camera-container').append(canvas);
            
            const displaySize = { width: video.videoWidth, height: video.videoHeight };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                if (!isModelsLoaded) return;

                const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 320, scoreThreshold: 0.2 });

                try {
                    const detections = await faceapi.detectAllFaces(video, options);

                    // 1. Clear the canvas
                    const ctx = canvas.getContext('2d');
                    ctx.clearRect(0, 0, canvas.width, canvas.height);

                    if (detections.length > 0) {
                        statusText.innerText = `Status: FACE DETECTED!`;
                        statusText.style.color = "#00FF00";
                        
                        const resizedDetections = faceapi.resizeResults(detections, displaySize);

                        // 2. FLIP THE DRAWING CONTEXT
                        // We save the current state, flip it, draw, and restore it.
                        ctx.save();
                        ctx.scale(-1, 1); // Flip horizontally
                        ctx.translate(-canvas.width, 0); // Move it back into frame

                        // 3. Draw the box (now it will match the mirrored video)
                        faceapi.draw.drawDetections(canvas, resizedDetections);
                        
                        ctx.restore(); // Restore to normal for next frame
                    } else {
                        statusText.innerText = "Status: Scanning...";
                        statusText.style.color = "yellow";
                    }
                } catch (err) {
                    console.log("Detection Error:", err);
                }
            }, 100);
        }
        // 4. DEMO BUTTON
        function analyzeUser() {
            const status = statusText.innerText;
            if (status.includes("FACE DETECTED")) {
                resultBox.style.display = "block";
                resultBox.innerHTML = "<strong>Gemini:</strong> Matching Face... Success! <br>Recommended Aid: <span style='color:#4285F4'>Winter Kit</span>";
            } else {
                alert("I can't see a face! Make sure the Status says 'FACE DETECTED' first.");
            }
        }
    </script>
</body>
</html>
